---
phase: 02-adapter-framework-codex-sync
plan: 03
type: execute
wave: 3
depends_on: ["02-01", "02-02"]
files_modified:
  - src/adapters/codex.py
autonomous: true
verification_level: proxy

must_haves:
  truths:
    - "sync_mcp translates JSON MCP server configs to TOML [mcp_servers.\"name\"] format that parses with tomllib"
    - "sync_mcp preserves environment variable references (${VAR}) as literal strings in generated TOML"
    - "sync_mcp handles both stdio (command/args) and HTTP (url) transport types"
    - "sync_mcp writes config.toml atomically using write_toml_atomic"
    - "sync_settings maps Claude Code permission settings to Codex sandbox_mode with conservative defaults"
    - "sync_settings uses most restrictive sandbox (read-only) when ANY tool is denied -- never downgrades security"
    - "sync_settings writes sandbox_mode and approval_policy to config.toml"
    - "Full CodexAdapter.sync_all produces correct SyncResult for all 6 config types"
    - "Integration test: SourceReader -> CodexAdapter.sync_all round-trip works end-to-end"
  artifacts:
    - path: "src/adapters/codex.py"
      provides: "Complete Codex adapter with all 6 sync methods"
      exports: ["CodexAdapter"]
      min_lines: 250
  key_links:
    - from: "src/adapters/codex.py"
      to: "src/utils/toml_writer.py"
      via: "TOML generation for MCP servers"
      pattern: "from src.utils.toml_writer import"
    - from: "src/adapters/codex.py"
      to: "src/source_reader.py"
      via: "integration test input"
      pattern: "SourceReader"
---

<objective>
Complete the Codex adapter by implementing MCP server translation (CDX-05) and permission mapping (CDX-06), then run an integration test validating the full pipeline from SourceReader through CodexAdapter.

Purpose: MCP servers are the most complex translation (JSON to TOML with env var preservation), and permission mapping is the most security-sensitive operation (conservative defaults prevent accidental privilege escalation). This plan completes all CDX requirements and validates the full adapter works end-to-end.

Output: Completed src/adapters/codex.py with all 6 sync methods implemented and verified.

Research basis: 02-RESEARCH.md Pattern 3 (Manual TOML Generation), Recommendation 2 (Manual TOML), Recommendation 4 (Conservative Permission Mapping), Codex MCP Servers in TOML (complete schema), Permission Model (sandbox modes). Pitfall avoidance for env var expansion (Pitfall 2), TOML escaping (Pitfall 1), permission downgrade (Pitfall 4), atomic writes (Pitfall 5).
</objective>

<execution_context>
@.planning/phases/02-adapter-framework-codex-sync/02-RESEARCH.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/REQUIREMENTS.md
@.planning/phases/02-adapter-framework-codex-sync/02-01-PLAN.md
@.planning/phases/02-adapter-framework-codex-sync/02-02-PLAN.md
@src/adapters/codex.py
@src/utils/toml_writer.py
@src/source_reader.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement MCP server translation and permission mapping</name>
  <files>src/adapters/codex.py</files>
  <action>
    Complete the CodexAdapter by replacing the sync_mcp and sync_settings stubs with full implementations.

    1. Add imports to codex.py:
       ```python
       import tomllib  # For reading existing config.toml
       from src.utils.toml_writer import (
           format_mcp_servers_toml,
           format_mcp_server_toml,
           write_toml_atomic,
           escape_toml_string,
       )
       ```

    2. Add constant:
       - `CONFIG_TOML = "codex.toml"` -- Codex config file name (per Codex docs, project-level config is in project root or .codex/)

    3. Implement `sync_mcp(self, mcp_servers: dict[str, dict]) -> SyncResult` (CDX-05):
       - If mcp_servers is empty, return SyncResult()
       - Config target path: `self.project_dir / ".codex" / CONFIG_TOML`
       - Read existing config.toml if it exists using tomllib (binary mode):
         - Extract existing mcp_servers section (if any)
         - Preserve non-MCP settings (sandbox_mode, approval_policy, etc.)
       - Merge new MCP servers with existing ones (new servers overwrite same-name entries)
       - Generate TOML for mcp_servers section using format_mcp_servers_toml
       - Combine preserved settings + generated MCP servers
       - Write atomically using write_toml_atomic
       - Track each server: synced if successful, failed if TOML generation fails
       - Return SyncResult with counts and config.toml path

       Handle both transport types per research:
       - stdio servers: have `command` and optional `args` fields
       - HTTP servers: have `url` field and optional `bearer_token_env_var`

       CRITICAL: Preserve env var references as-is. Do NOT expand `${VAR}` during sync (Pitfall 2).

    4. Add helper `_read_existing_config(self) -> dict`:
       - Read config.toml with tomllib if it exists
       - Return empty dict if file missing or parse error
       - Use try/except tomllib.TOMLDecodeError for graceful degradation

    5. Add helper `_build_config_toml(self, settings_section: str, mcp_section: str) -> str`:
       - Combine settings and MCP sections into a complete config.toml string
       - Add header comment: `# Codex configuration managed by HarnessSync\n# Do not edit MCP servers section manually\n\n`
       - Settings section first, then blank line, then MCP section

    6. Implement `sync_settings(self, settings: dict) -> SyncResult` (CDX-06):
       - If settings is empty, return SyncResult()
       - Map Claude Code permission settings to Codex sandbox mode:

         **Permission Mapping Logic (per research Recommendation 4: Conservative):**

         a. Extract tool permissions from settings (settings may have 'permissions' or 'allowedTools' keys)
         b. Determine sandbox_mode based on most restrictive tool permission:
            - If ANY tool is explicitly denied: `sandbox_mode = "read-only"` (most restrictive)
            - If all tools allowed and includes file write: `sandbox_mode = "workspace-write"`
            - Default (no explicit permissions): `sandbox_mode = "workspace-write"` (Codex default)
            - NEVER map to `"danger-full-access"` automatically -- user must set this manually

         c. Map approval_policy:
            - Claude Code "ask" permission mode -> Codex `"on-request"` (default)
            - Claude Code "auto" permission mode -> Codex `"on-failure"`
            - Default: `"on-request"` (conservative)

       - Format settings as TOML key-value pairs:
         ```toml
         sandbox_mode = "workspace-write"
         approval_policy = "on-request"
         ```
       - Read existing config.toml, preserve MCP servers section
       - Write combined content atomically
       - Return SyncResult(synced=1, adapted=1, synced_files=[str(config_path)])
       - Add to skipped_files any settings that couldn't be mapped with reason

    Avoid:
    - Do NOT map to "danger-full-access" automatically -- this is a security risk (Pitfall 4)
    - Do NOT expand environment variables -- preserve ${VAR} as-is (Pitfall 2)
    - Do NOT overwrite entire config.toml -- merge with existing content
    - Do NOT assume config.toml exists -- create .codex/ directory if needed
    - Do NOT use non-atomic writes for config.toml -- Codex parses this at startup (Pitfall 5)
  </action>
  <verify>
    Run from project root (Level 2: Proxy):
    ```bash
    python3 -c "
    import tempfile, shutil, tomllib
    from pathlib import Path
    from src.adapters.codex import CodexAdapter

    tmp = Path(tempfile.mkdtemp())
    adapter = CodexAdapter(tmp)

    # Test 1: sync_mcp with stdio server
    mcp_servers = {
        'filesystem': {
            'command': 'node',
            'args': ['mcp-server-filesystem', '/home/user'],
            'env': {'NODE_ENV': 'production'},
            'enabled': True,
        },
    }
    result = adapter.sync_mcp(mcp_servers)
    assert result.synced >= 1, f'Expected synced >= 1, got {result.synced}'

    config_path = tmp / '.codex' / 'codex.toml'
    assert config_path.exists(), 'config.toml not created'
    with open(config_path, 'rb') as f:
        parsed = tomllib.load(f)
    assert 'mcp_servers' in parsed
    assert 'filesystem' in parsed['mcp_servers']
    srv = parsed['mcp_servers']['filesystem']
    assert srv['command'] == 'node'
    assert srv['args'] == ['mcp-server-filesystem', '/home/user']
    assert srv['env']['NODE_ENV'] == 'production'
    print('sync_mcp stdio: OK')

    # Test 2: sync_mcp with env var preservation
    mcp_env = {
        'api-server': {
            'command': 'python',
            'args': ['-m', 'mcp_api'],
            'env': {
                'API_KEY': '\${API_KEY}',
                'SECRET': '\${MY_SECRET}',
            },
        },
    }
    result2 = adapter.sync_mcp(mcp_env)
    with open(config_path, 'rb') as f:
        parsed2 = tomllib.load(f)
    assert parsed2['mcp_servers']['api-server']['env']['API_KEY'] == '\${API_KEY}'
    assert parsed2['mcp_servers']['api-server']['env']['SECRET'] == '\${MY_SECRET}'
    # Previous server should still be there (merge, not overwrite)
    assert 'filesystem' in parsed2['mcp_servers']
    print('Env var preservation + merge: OK')

    # Test 3: sync_mcp with HTTP server
    mcp_http = {
        'remote-api': {
            'url': 'https://api.example.com/mcp',
            'bearer_token_env_var': 'MCP_TOKEN',
        },
    }
    result3 = adapter.sync_mcp(mcp_http)
    with open(config_path, 'rb') as f:
        parsed3 = tomllib.load(f)
    assert 'remote-api' in parsed3['mcp_servers']
    assert parsed3['mcp_servers']['remote-api']['url'] == 'https://api.example.com/mcp'
    print('HTTP server: OK')

    # Test 4: sync_mcp empty
    result4 = adapter.sync_mcp({})
    assert result4.synced == 0
    print('Empty MCP: OK')

    # Test 5: sync_settings conservative mapping
    settings = {
        'permissions': {
            'allow': ['Bash', 'Read', 'Write'],
            'deny': ['WebSearch'],
        }
    }
    result5 = adapter.sync_settings(settings)
    assert result5.synced >= 1, f'Expected synced >= 1, got {result5.synced}'
    with open(config_path, 'rb') as f:
        parsed5 = tomllib.load(f)
    # With ANY denied tool, should be most restrictive
    assert parsed5.get('sandbox_mode') == 'read-only', f'Expected read-only, got {parsed5.get(\"sandbox_mode\")}'
    print('Conservative permissions: OK')

    # Test 6: sync_settings with all allowed -> workspace-write
    adapter2 = CodexAdapter(Path(tempfile.mkdtemp()))
    settings2 = {
        'permissions': {
            'allow': ['Bash', 'Read', 'Write'],
        }
    }
    result6 = adapter2.sync_settings(settings2)
    config2 = adapter2.project_dir / '.codex' / 'codex.toml'
    with open(config2, 'rb') as f:
        parsed6 = tomllib.load(f)
    assert parsed6.get('sandbox_mode') == 'workspace-write'
    print('Permissive settings: OK')

    # Test 7: sync_settings empty
    adapter3 = CodexAdapter(Path(tempfile.mkdtemp()))
    result7 = adapter3.sync_settings({})
    assert result7.synced == 0
    print('Empty settings: OK')

    # Test 8: Settings preserved when MCP synced after
    adapter4 = CodexAdapter(Path(tempfile.mkdtemp()))
    adapter4.sync_settings({'permissions': {'allow': ['Bash']}})
    adapter4.sync_mcp({'test-srv': {'command': 'test'}})
    config4 = adapter4.project_dir / '.codex' / 'codex.toml'
    with open(config4, 'rb') as f:
        parsed8 = tomllib.load(f)
    assert 'sandbox_mode' in parsed8, 'Settings lost after MCP sync'
    assert 'mcp_servers' in parsed8, 'MCP lost after settings were there'
    print('Settings + MCP coexistence: OK')

    shutil.rmtree(tmp)
    print('Codex Adapter (MCP+Settings): ALL CHECKS PASSED')
    "
    ```
  </verify>
  <done>CodexAdapter.sync_mcp translates MCP servers from JSON to TOML [mcp_servers."name"] format with env var preservation, handles stdio and HTTP transports, merges with existing config. sync_settings maps Claude Code permissions to Codex sandbox_mode with conservative defaults (any deny -> read-only, never auto-maps to danger-full-access). Config.toml written atomically. All 8 verification assertions pass.</done>
</task>

<task type="auto">
  <name>Task 2: Run Phase 2 integration verification</name>
  <files>src/adapters/codex.py</files>
  <action>
    Run a comprehensive integration test that validates the full Phase 2 pipeline: SourceReader discovers configs, CodexAdapter processes all 6 types, SyncResult reports accurately, and generated files are valid.

    The integration test should:

    1. Create a mock project directory with all 6 Claude Code config types:
       - CLAUDE.md with project rules
       - .claude/CLAUDE.md with local rules
       - .claude/skills/format-code/ with SKILL.md
       - .claude/agents/reviewer.md (full agent with frontmatter + role)
       - .claude/commands/deploy.md (command with frontmatter)
       - .mcp.json with 2 MCP servers (one stdio, one with env vars)
       - .claude/settings.json with permission settings

    2. Use SourceReader to discover all configs from mock project

    3. Use AdapterRegistry.get_adapter("codex", project_dir) to get CodexAdapter

    4. Call adapter.sync_all() with discovered configs

    5. Verify all outputs:
       a. AGENTS.md exists with rules content and HarnessSync markers
       b. .agents/skills/format-code/ exists (symlink or copy)
       c. .agents/skills/agent-reviewer/SKILL.md exists with converted content
       d. .agents/skills/cmd-deploy/SKILL.md exists with converted content
       e. .codex/codex.toml exists and parses with tomllib
       f. codex.toml has mcp_servers section with both servers
       g. codex.toml has sandbox_mode setting

    6. Verify SyncResult accuracy:
       a. Rules: synced=1, adapted matches rule file count
       b. Skills: synced matches skill count
       c. Agents: synced and adapted match agent count
       d. Commands: synced and adapted match command count
       e. MCP: synced matches server count
       f. Settings: synced=1

    7. Verify idempotency: Run sync_all again, skills should report skipped

    This is a verification-only task. No code changes -- just run the integration test inline as a verification script. If any assertion fails, document the failure and fix the code.

    IMPORTANT: The SourceReader returns specific data shapes. Make sure the integration test constructs mock data in the exact format CodexAdapter expects:
    - rules: list of dicts with 'path' and 'content' keys
    - skills: dict of name -> Path
    - agents: dict of name -> Path
    - commands: dict of name -> Path
    - mcp: dict of name -> server config dict
    - settings: dict with permission settings
  </action>
  <verify>
    Run from project root (Level 2: Proxy):
    ```bash
    python3 -c "
    import tempfile, shutil, json, tomllib
    from pathlib import Path

    # === Setup mock project ===
    tmp = Path(tempfile.mkdtemp())

    # Rules
    (tmp / 'CLAUDE.md').write_text('# Project Rules\n\nBe concise. Use Python 3.')
    claude_dir = tmp / '.claude'
    claude_dir.mkdir()
    (claude_dir / 'CLAUDE.md').write_text('# Local Rules\n\nPrefer pathlib over os.path.')

    # Skills
    skill_dir = claude_dir / 'skills' / 'format-code'
    skill_dir.mkdir(parents=True)
    (skill_dir / 'SKILL.md').write_text('---\nname: format-code\ndescription: Format code\n---\nRun black.')

    # Agents
    agent_dir = claude_dir / 'agents'
    agent_dir.mkdir()
    (agent_dir / 'reviewer.md').write_text('''---
name: code-reviewer
description: Reviews code quality
tools: Read, Grep
color: blue
---

<role>
You review code for quality. Check:
1. Style
2. Bugs
3. Performance
</role>
''')

    # Commands
    cmd_dir = claude_dir / 'commands'
    cmd_dir.mkdir()
    (cmd_dir / 'deploy.md').write_text('''---
name: deploy
description: Deploy to production
---

Steps:
1. Run tests
2. Build
3. Deploy to staging
4. Promote to prod
''')

    # MCP servers
    mcp_config = {
        'mcpServers': {
            'filesystem': {
                'command': 'node',
                'args': ['mcp-server-filesystem', '/project'],
                'env': {'NODE_PATH': '/usr/lib/node'},
            },
            'api-bridge': {
                'command': 'python',
                'args': ['-m', 'mcp_bridge'],
                'env': {'API_TOKEN': '\${API_TOKEN}'},
                'enabled': True,
            },
        }
    }
    (tmp / '.mcp.json').write_text(json.dumps(mcp_config, indent=2))

    # Settings
    settings = {
        'permissions': {
            'allow': ['Bash', 'Read', 'Write', 'Edit'],
            'deny': ['WebSearch'],
        }
    }
    (claude_dir / 'settings.json').write_text(json.dumps(settings, indent=2))

    # === Discover configs (simulating SourceReader output) ===
    # Note: We manually construct the data shapes here since SourceReader
    # reads from specific paths that may not match our mock structure exactly
    rules = [
        {'path': tmp / 'CLAUDE.md', 'content': (tmp / 'CLAUDE.md').read_text()},
        {'path': claude_dir / 'CLAUDE.md', 'content': (claude_dir / 'CLAUDE.md').read_text()},
    ]
    skills = {'format-code': skill_dir}
    agents = {'reviewer': agent_dir / 'reviewer.md'}
    commands = {'deploy': cmd_dir / 'deploy.md'}
    mcp_servers = mcp_config['mcpServers']
    settings_data = settings

    # === Run sync ===
    from src.adapters import AdapterRegistry, SyncResult

    # Import codex module to trigger registration
    import src.adapters.codex

    adapter = AdapterRegistry.get_adapter('codex', tmp)
    source_data = {
        'rules': rules,
        'skills': skills,
        'agents': agents,
        'commands': commands,
        'mcp': mcp_servers,
        'settings': settings_data,
    }
    results = adapter.sync_all(source_data)

    # === Verify results ===
    print('\\n=== Phase 2 Integration Test ===\\n')

    # 1. Rules
    r = results['rules']
    assert r.synced == 1, f'Rules: expected synced=1, got {r.synced}'
    agents_md = tmp / 'AGENTS.md'
    assert agents_md.exists(), 'AGENTS.md not created'
    agents_content = agents_md.read_text()
    assert 'Be concise' in agents_content
    assert 'pathlib' in agents_content
    assert 'Managed by HarnessSync' in agents_content
    print(f'Step 1: Rules synced (synced={r.synced}, adapted={r.adapted}) OK')

    # 2. Skills
    r = results['skills']
    assert r.synced >= 1 or r.skipped >= 1, f'Skills: expected synced or skipped, got {r}'
    target_skill = tmp / '.agents' / 'skills' / 'format-code'
    assert target_skill.exists() or target_skill.is_symlink()
    print(f'Step 2: Skills synced (synced={r.synced}, skipped={r.skipped}) OK')

    # 3. Agents
    r = results['agents']
    assert r.synced == 1, f'Agents: expected synced=1, got {r.synced}'
    assert r.adapted == 1, f'Agents: expected adapted=1, got {r.adapted}'
    agent_skill = tmp / '.agents' / 'skills' / 'agent-reviewer' / 'SKILL.md'
    assert agent_skill.exists(), 'Agent SKILL.md not created'
    agent_content = agent_skill.read_text()
    assert 'code-reviewer' in agent_content
    assert 'tools:' not in agent_content, 'Claude-specific tools field leaked'
    print(f'Step 3: Agents converted (synced={r.synced}, adapted={r.adapted}) OK')

    # 4. Commands
    r = results['commands']
    assert r.synced == 1, f'Commands: expected synced=1, got {r.synced}'
    cmd_skill = tmp / '.agents' / 'skills' / 'cmd-deploy' / 'SKILL.md'
    assert cmd_skill.exists(), 'Command SKILL.md not created'
    assert 'deploy' in cmd_skill.read_text().lower()
    print(f'Step 4: Commands converted (synced={r.synced}, adapted={r.adapted}) OK')

    # 5. MCP servers
    r = results['mcp']
    assert r.synced >= 1, f'MCP: expected synced >= 1, got {r.synced}'
    config_toml = tmp / '.codex' / 'codex.toml'
    assert config_toml.exists(), 'codex.toml not created'
    with open(config_toml, 'rb') as f:
        parsed = tomllib.load(f)
    assert 'mcp_servers' in parsed, 'No mcp_servers in config.toml'
    assert 'filesystem' in parsed['mcp_servers']
    assert 'api-bridge' in parsed['mcp_servers']
    assert parsed['mcp_servers']['api-bridge']['env']['API_TOKEN'] == '\${API_TOKEN}'
    print(f'Step 5: MCP translated (synced={r.synced}) OK')

    # 6. Settings
    r = results['settings']
    assert r.synced >= 1, f'Settings: expected synced >= 1, got {r.synced}'
    with open(config_toml, 'rb') as f:
        parsed2 = tomllib.load(f)
    assert 'sandbox_mode' in parsed2, 'No sandbox_mode in config.toml'
    assert parsed2['sandbox_mode'] == 'read-only', f'Expected read-only (deny present), got {parsed2[\"sandbox_mode\"]}'
    print(f'Step 6: Settings mapped (sandbox_mode={parsed2[\"sandbox_mode\"]}) OK')

    # 7. Idempotency check
    results2 = adapter.sync_all(source_data)
    r_skills2 = results2['skills']
    assert r_skills2.skipped >= 1, f'Idempotency: skills should be skipped on re-sync, got synced={r_skills2.synced}'
    print(f'Step 7: Idempotency verified (skills skipped={r_skills2.skipped}) OK')

    # Summary
    total_synced = sum(r.synced for r in results.values())
    total_adapted = sum(r.adapted for r in results.values())
    total_failed = sum(r.failed for r in results.values())
    print(f'\\n=== Integration Summary ===')
    print(f'Total synced: {total_synced}')
    print(f'Total adapted: {total_adapted}')
    print(f'Total failed: {total_failed}')
    assert total_failed == 0, f'Integration test had failures!'

    shutil.rmtree(tmp)
    print('\\nPhase 2 Integration: ALL CHECKS PASSED')
    "
    ```
  </verify>
  <done>Full Phase 2 integration test passes: SourceReader-shaped data -> CodexAdapter.sync_all -> all 6 config types synced correctly. AGENTS.md has markers, skills symlinked, agents/commands converted to SKILL.md, MCP servers in valid TOML, permissions conservatively mapped. Idempotency verified. Zero failures. All Phase 2 requirements (ADP-01, ADP-02, ADP-03, CDX-01 through CDX-06) delivered.</done>
</task>

</tasks>

<verification>
Level 1 (Sanity):
- codex.toml parses with tomllib without errors
- sandbox_mode is never "danger-full-access" unless user explicitly sets it

Level 2 (Proxy):
- MCP servers round-trip through TOML generation + tomllib parsing with identical values
- Environment variables preserved as literal ${VAR} strings (not expanded)
- Settings and MCP sections coexist in same config.toml without overwriting each other
- Full 7-step integration test passes (rules, skills, agents, commands, mcp, settings, idempotency)
- Conservative permission mapping: any denied tool -> read-only sandbox

Level 3 (Deferred): Codex CLI actually reads generated config.toml and respects settings, skills load correctly
</verification>

<success_criteria>
- sync_mcp generates valid TOML that parses with tomllib
- sync_mcp preserves env var references as literal strings
- sync_mcp handles both stdio and HTTP transports
- sync_mcp merges with existing config.toml (preserves settings)
- sync_settings uses conservative mapping (deny -> read-only)
- sync_settings never auto-maps to danger-full-access
- Config.toml written atomically
- 7-step integration test passes with zero failures
- All 9 Phase 2 requirements (ADP-01/02/03, CDX-01/02/03/04/05/06) verified
- No external dependencies
</success_criteria>

<output>
After completion, create `.planning/phases/02-adapter-framework-codex-sync/02-03-SUMMARY.md`
</output>
