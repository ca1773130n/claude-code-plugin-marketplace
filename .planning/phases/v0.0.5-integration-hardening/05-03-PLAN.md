---
phase: 05-integration-hardening
plan: 03
type: execute
wave: 2
depends_on: ["05-01", "05-02"]
files_modified:
  - .github/workflows/self-test.yml
  - scripts/README.md
autonomous: true
verification_level: proxy

must_haves:
  truths:
    - "self-test.yml triggers on push to main (scripts/schemas/tests paths), on PR (same paths), on workflow_dispatch, and on weekly schedule"
    - "self-test.yml has 3 parallel jobs: fixture-tests, e2e-test, script-help-check"
    - "fixture-tests job runs npm ci then ./scripts/run-fixture-tests.sh"
    - "e2e-test job runs npm ci then ./scripts/run-e2e-test.sh"
    - "script-help-check job verifies all scripts/*.sh exit 0 on --help"
    - "scripts/README.md documents all 7 scripts with usage, purpose, exit codes, and examples"
    - "self-test.yml is valid YAML and follows the repository's existing workflow patterns"
    - "Local pipeline execution (fixture tests + E2E + help check) completes in < 60 seconds, leaving headroom for CI overhead to stay under 2 minutes total"
  artifacts:
    - path: ".github/workflows/self-test.yml"
      provides: "Self-test CI workflow with 3 parallel jobs and 4 triggers"
      contains: "workflow_dispatch"
    - path: "scripts/README.md"
      provides: "Documentation for all scripts with usage reference"
      contains: "run-e2e-test.sh"
  key_links:
    - from: ".github/workflows/self-test.yml"
      to: "scripts/run-fixture-tests.sh"
      via: "job step invocation"
      pattern: "run-fixture-tests\\.sh"
    - from: ".github/workflows/self-test.yml"
      to: "scripts/run-e2e-test.sh"
      via: "job step invocation"
      pattern: "run-e2e-test\\.sh"
    - from: "scripts/README.md"
      to: "scripts/validate-plugin.sh"
      via: "documentation reference"
      pattern: "validate-plugin\\.sh"
    - from: "scripts/README.md"
      to: "scripts/score-plugin.sh"
      via: "documentation reference"
      pattern: "score-plugin\\.sh"
---

<objective>
Create the self-test CI workflow and comprehensive script documentation.

Purpose: The self-test workflow catches infrastructure regressions even when no plugins change -- it runs fixture tests, the E2E pipeline test, and a --help compliance check on every push/PR that touches scripts, schemas, or test fixtures. The scripts/README.md provides a single-file reference for all 7 scripts in the repository, including usage, purpose, exit codes, and examples.

Output: `.github/workflows/self-test.yml` and `scripts/README.md`.
</objective>

<execution_context>
@${CLAUDE_PLUGIN_ROOT}/references/execute-plan.md
@${CLAUDE_PLUGIN_ROOT}/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-integration-hardening/05-RESEARCH.md

# Existing workflows (for pattern consistency)
@.github/workflows/validate-plugins.yml
@.github/workflows/publish-marketplace.yml

# All scripts (for README documentation)
@scripts/validate-plugin.sh
@scripts/score-plugin.sh
@scripts/run-fixture-tests.sh
@scripts/generate-marketplace.sh
@scripts/validate-local.sh
@scripts/new-plugin.sh
@scripts/run-e2e-test.sh
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create self-test.yml GitHub Actions workflow</name>
  <files>.github/workflows/self-test.yml</files>
  <action>
    Create `.github/workflows/self-test.yml` -- a CI workflow that tests the marketplace infrastructure itself.

    Follow the pattern established in the existing workflows (validate-plugins.yml, publish-marketplace.yml):
    - Uses `actions/checkout@v4`
    - Uses `actions/setup-node@v4` with `node-version: '20'` and `cache: 'npm'`
    - Runs `npm ci` before script invocations

    **Workflow structure:**

    ```yaml
    name: Self Test

    on:
      push:
        branches: [main]
        paths:
          - 'scripts/**'
          - 'schemas/**'
          - 'tests/**'
      pull_request:
        branches: [main]
        paths:
          - 'scripts/**'
          - 'schemas/**'
          - 'tests/**'
      workflow_dispatch: {}
      schedule:
        - cron: '0 6 * * 1'   # Weekly Monday 6am UTC
    ```

    **Three parallel jobs:**

    1. **fixture-tests** -- Runs the fixture test suite:
       ```yaml
       fixture-tests:
         name: Fixture Tests
         runs-on: ubuntu-latest
         steps:
           - uses: actions/checkout@v4
           - uses: actions/setup-node@v4
             with:
               node-version: '20'
               cache: 'npm'
           - run: npm ci
           - name: Run fixture tests
             run: ./scripts/run-fixture-tests.sh
       ```

    2. **e2e-test** -- Runs the end-to-end pipeline test:
       ```yaml
       e2e-test:
         name: E2E Pipeline Test
         runs-on: ubuntu-latest
         steps:
           - uses: actions/checkout@v4
           - uses: actions/setup-node@v4
             with:
               node-version: '20'
               cache: 'npm'
           - run: npm ci
           - name: Run E2E pipeline test
             run: ./scripts/run-e2e-test.sh
       ```

    3. **script-help-check** -- Verifies all scripts support --help with exit 0:
       ```yaml
       script-help-check:
         name: Script Help Check
         runs-on: ubuntu-latest
         steps:
           - uses: actions/checkout@v4
           - name: Verify all scripts support --help
             run: |
               failed=0
               for script in scripts/*.sh; do
                 exit_code=0
                 ./"$script" --help >/dev/null 2>&1 || exit_code=$?
                 if [ "$exit_code" -ne 0 ]; then
                   echo "FAIL: $script --help exited with $exit_code (expected 0)"
                   failed=1
                 else
                   echo "PASS: $script --help"
                 fi
               done
               exit $failed
       ```

    Note: The script-help-check job does NOT need `npm ci` or `setup-node` because it only runs `--help` on each script (which shows usage and exits before any actual work).

    All three jobs run in parallel (no `needs:` dependencies between them).
  </action>
  <verify>
    Verify YAML syntax: `python3 -c "import yaml; yaml.safe_load(open('.github/workflows/self-test.yml'))"` or equivalent. (Level 1: Sanity)
    Verify file contains all 4 triggers: grep for `push:`, `pull_request:`, `workflow_dispatch:`, `schedule:`. (Level 1: Sanity)
    Verify file contains all 3 job names: grep for `fixture-tests:`, `e2e-test:`, `script-help-check:`. (Level 1: Sanity)
    Verify file references correct scripts: grep for `run-fixture-tests.sh`, `run-e2e-test.sh`. (Level 1: Sanity)
    Verify the paths filter includes `scripts/**`, `schemas/**`, `tests/**`. (Level 1: Sanity)
    Actual CI execution is deferred to post-push to GitHub. (Level 2: Proxy)
  </verify>
  <done>self-test.yml exists with 4 triggers (push, PR, workflow_dispatch, weekly schedule), 3 parallel jobs (fixture-tests, e2e-test, script-help-check), and follows the repository's existing workflow patterns.</done>
</task>

<task type="auto">
  <name>Task 2: Create scripts/README.md documenting all scripts</name>
  <files>scripts/README.md</files>
  <action>
    Create `scripts/README.md` -- comprehensive documentation for all 7 scripts in the `scripts/` directory.

    **Structure:**

    1. **Header:**
       ```markdown
       # Scripts Reference

       This directory contains all CLI scripts for the Claude Code Plugin Marketplace.
       All scripts follow consistent conventions: `--help` for usage (exit 0),
       exit 2 on invalid arguments, exit 1 on operational failure.

       ## Prerequisites

       Run `npm ci` before using any script (required for ajv-cli JSON Schema validation).
       ```

    2. **Quick Reference table:**
       ```markdown
       ## Quick Reference

       | Script | Purpose | Arguments | Exit Codes |
       |--------|---------|-----------|------------|
       | validate-plugin.sh | Validate plugin structure and manifest | `<plugin-dir>` | 0=pass, 1=fail, 2=usage |
       | score-plugin.sh | Score plugin quality (0-100) | `<plugin-dir> [--json]` | 0=scored, 2=usage |
       | validate-local.sh | Validate + score (contributor wrapper) | `<plugin-dir>` | 0=pass, 1=fail, 2=usage |
       | new-plugin.sh | Scaffold new plugin from template | `<name> [--description] [--author]` | 0=created, 1=error, 2=usage |
       | generate-marketplace.sh | Regenerate marketplace.json | (none) | 0=generated, 1=error, 2=usage |
       | run-fixture-tests.sh | Run validation test fixtures | (none) | 0=pass, 1=fail, 2=usage |
       | run-e2e-test.sh | End-to-end pipeline test | (none) | 0=pass, 1=fail, 2=usage |
       ```

    3. **Detailed section for each script** (in order of typical usage):

       For each script, include:
       - **Purpose** (1-2 sentences)
       - **Usage** (command-line syntax)
       - **Options** (flags and arguments)
       - **Examples** (1-3 concrete examples)
       - **Exit Codes** (with descriptions)

       Scripts to document (in this order):
       a. `validate-plugin.sh` -- Two-layer validation (schema via ajv-cli + structural checks)
       b. `score-plugin.sh` -- 5-category quality scoring, 100-point scale, --json for machine output
       c. `validate-local.sh` -- Convenience wrapper for contributors (runs validate then score)
       d. `new-plugin.sh` -- Scaffolds from templates/plugin-template/, generates all files via jq
       e. `generate-marketplace.sh` -- Builds .claude-plugin/marketplace.json from all plugins
       f. `run-fixture-tests.sh` -- Runs 11 fixture tests (4 valid + 4 invalid + 1 extra-fields + 2 real)
       g. `run-e2e-test.sh` -- Full pipeline test: scaffold -> validate -> score -> generate -> verify -> cleanup

    4. **Conventions section:**
       ```markdown
       ## Conventions

       All scripts follow these patterns:
       - Shebang: `#!/usr/bin/env bash`
       - Error handling: `set -euo pipefail`
       - Path resolution: `SCRIPT_DIR` and `REPO_ROOT` via `cd + pwd`
       - macOS bash 3.x compatible (no associative arrays, no GNU-specific flags)
       - `--help` / `-h` prints usage and exits 0
       - Unknown arguments exit 2 with error message to stderr
       - Operational failures exit 1
       ```

    5. **CI Integration section:**
       ```markdown
       ## CI Integration

       These scripts are invoked by GitHub Actions workflows:
       - `validate-plugins.yml` -- Runs validate-plugin.sh and score-plugin.sh on PRs
       - `publish-marketplace.yml` -- Runs generate-marketplace.sh on merge to main
       - `self-test.yml` -- Runs run-fixture-tests.sh, run-e2e-test.sh, and --help checks
       ```

    The README should be informational and practical. Target 120-180 lines. Cross-reference each script's actual --help output to ensure accuracy (run each script with --help to verify the documented usage matches).

    IMPORTANT: Do NOT include emojis. Use plain markdown formatting.
  </action>
  <verify>
    Verify file exists: `test -s scripts/README.md`. (Level 1: Sanity)
    Verify all 7 scripts are mentioned: grep for each script name in the README. (Level 1: Sanity)
    Verify README is >= 100 lines: `wc -l scripts/README.md` shows >= 100. (Level 1: Sanity)
    Cross-check: Run `./scripts/validate-plugin.sh --help` and verify README describes the same usage pattern. (Level 1: Sanity)
    Verify no emojis in the file. (Level 1: Sanity)
  </verify>
  <done>scripts/README.md exists with >= 100 lines, documents all 7 scripts with purpose, usage, examples, exit codes, conventions, and CI integration sections. All documented usage matches actual --help output.</done>
</task>

<task type="auto">
  <name>Task 3: Measure local pipeline performance and verify CI time budget</name>
  <files>(no new files -- runs existing scripts and reports timing)</files>
  <action>
    Measure the wall-clock time of each CI job's local equivalent to verify the pipeline fits within the 2-minute CI budget.

    Run the following three commands sequentially, timing each one:

    1. **Fixture tests** (mirrors the fixture-tests CI job):
       ```bash
       time ./scripts/run-fixture-tests.sh
       ```
       Expected: ~5s based on research baseline (11 tests at ~0.4s each).

    2. **E2E pipeline test** (mirrors the e2e-test CI job):
       ```bash
       time ./scripts/run-e2e-test.sh
       ```
       Expected: ~10s based on research baseline (5-plugin pipeline at ~9.5s).

    3. **Script help check** (mirrors the script-help-check CI job):
       ```bash
       time (for s in scripts/*.sh; do ./"$s" --help >/dev/null 2>&1; done)
       ```
       Expected: < 1s (7 scripts, each exits immediately on --help).

    **Budget analysis:**
    The three CI jobs run in parallel, so total CI time = max(job1, job2, job3) + npm ci overhead.
    - Longest job (E2E): ~10s local
    - npm ci overhead: ~30s (estimated from research)
    - Total CI estimate: ~40s, well under 2-minute target

    Record the measured times and verify:
    - Each individual job completes in < 30 seconds locally
    - The longest job + 30s npm ci overhead < 120 seconds (2 minutes)

    If any job exceeds 30 seconds, investigate and document the bottleneck. The actual CI timing is deferred (requires GitHub Actions run) but this local measurement provides a reliable proxy.

    NOTE: This task produces no new files. It is a measurement/verification step whose results are recorded in the plan summary.
  </action>
  <verify>
    Run all three timed commands above and capture output. (Level 2: Proxy)
    Verify: max(fixture_time, e2e_time, help_time) + 30s < 120s. (Level 2: Proxy)
    Actual CI time verification deferred to first GitHub Actions run. (Level 3: Deferred)
  </verify>
  <done>All three pipeline components measured locally. Longest job + 30s CI overhead is < 120 seconds, confirming the 2-minute CI budget is achievable. Times documented in plan summary.</done>
</task>

</tasks>

<verification>
Level 1 (Sanity):
- self-test.yml is valid YAML
- self-test.yml has 4 triggers and 3 parallel jobs
- scripts/README.md exists and documents all 7 scripts
- scripts/README.md is >= 100 lines

Level 2 (Proxy):
- self-test.yml follows the same patterns as validate-plugins.yml (checkout, setup-node, npm ci)
- scripts/README.md usage descriptions match actual --help output
- self-test.yml completes successfully on GitHub Actions (deferred to post-push)

Level 3 (Deferred):
- Weekly scheduled run fires and passes (requires 1+ week observation)
- CI workflow time < 2 minutes (requires actual GitHub Actions run)
- self-test.yml completes all 3 parallel jobs in < 2 minutes on GitHub Actions
</verification>

<success_criteria>
- self-test.yml catches infrastructure regressions on push/PR to scripts/schemas/tests paths
- self-test.yml can be triggered manually via workflow_dispatch for debugging
- Three parallel jobs maximize CI throughput (fixture-tests, e2e-test, script-help-check)
- scripts/README.md serves as single-file reference for all marketplace scripts
- All documentation is accurate and matches actual script behavior
- Local pipeline timing confirms CI time budget < 2 minutes is achievable (longest job + 30s overhead < 120s)
</success_criteria>

<output>
After completion, create `.planning/phases/05-integration-hardening/05-03-SUMMARY.md`
</output>
